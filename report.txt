Title
Time Series Forecasting of Household Power Consumption Using SARIMA and Attention-Based LSTM


Abstract
Electric power consumption forecasting plays an important role in energy planning and management. In this project, household power consumption data is analyzed using time series forecasting techniques. Initially, a traditional statistical model called SARIMA is implemented as a baseline model. Further, a deep learning based Attention LSTM model is developed to capture temporal dependencies in multivariate time series data. The dataset is preprocessed using normalization and time-based train-test splitting to avoid data leakage. Model performance is evaluated using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). Experimental results show that the Attention LSTM model provides better forecasting accuracy compared to the baseline SARIMA model.

1. Introduction
Time series forecasting is the process of predicting future values based on previously observed data. Accurate forecasting of electricity consumption is essential for efficient power generation, load balancing, and energy conservation. Traditional statistical models perform well on simple patterns but struggle with complex temporal dependencies. With the advancement of machine learning, deep learning models such as LSTM have shown better performance in handling sequential data. In this project, both statistical and deep learning approaches are explored and compared.

2. Dataset Description
The dataset used in this project contains household power consumption measurements. The following features are selected for analysis:
Global_active_power
Global_reactive_power
Voltage
Global_intensity
Missing values are removed to ensure data quality. Since the dataset represents time series data, a time-based split is used instead of random shuffling.

3. Data Preprocessing
Data preprocessing is an important step to ensure reliable model performance. The following steps are applied:
Selection of relevant multivariate features
Removal of missing values
Normalization using MinMaxScaler
Time-based train-test split (80% training, 20% testing)
This approach ensures that future information is not leaked into the training phase.

4. Methodology
4.1 Baseline Model – SARIMA
SARIMA (Seasonal AutoRegressive Integrated Moving Average) is a statistical time series model commonly used for forecasting. In this project, SARIMA is applied on the target variable (Global Active Power) as a baseline model. It helps in comparing traditional forecasting performance with deep learning models.
4.2 Proposed Model – Attention Based LSTM
LSTM networks are designed to capture long-term dependencies in sequential data. To further enhance performance, an attention mechanism is added. The attention layer helps the model focus on important time steps instead of treating all time steps equally. The proposed model uses multivariate input and generates a single output prediction.

5. Model Training
SARIMA model is trained using training data only
Attention LSTM model is trained using time-series sequences
Optimizer used: Adam
Loss function: Mean Squared Error (MSE)
The models are trained carefully to avoid overfitting and data leakage.

6. Evaluation Metrics
The following metrics are used to evaluate model performance:
Mean Absolute Error (MAE) – Measures average absolute prediction error
Root Mean Squared Error (RMSE) – Penalizes large errors more heavily
These metrics are widely used in regression-based forecasting problems.

7. Results and Discussion
The SARIMA model provides reasonable predictions but struggles with complex patterns in the data. The Attention LSTM model achieves lower MAE and RMSE values, indicating better forecasting accuracy. The improvement is due to the model’s ability to learn temporal relationships and focus on important time steps using attention.

8. Conclusion
In this project, household power consumption forecasting is performed using both statistical and deep learning approaches. SARIMA is used as a baseline model, while an Attention-based LSTM is implemented as the proposed solution. Experimental results show that the deep learning model outperforms the traditional model. Future work may include using larger datasets and experimenting with advanced attention mechanisms.

9. Future Scope
Use of longer time series data
Hyperparameter tuning
Visualization of attention weights
Deployment of model for real-time forecasting

10. References
Box, G. E. P., Jenkins, G. M., Time Series Analysis, Wiley
Hochreiter, S., Schmidhuber, J., “Long Short-Term Memory”, Neural Computation
Brownlee, J., Deep Learning for Time Series Forecasting