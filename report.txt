Title
Time Series Forecasting of Household Power Consumption Using SARIMA and Attention-Based LSTM


Abstract
Electric power consumption forecasting plays an important role in energy planning and management. In this project, household power consumption data is analyzed using time series forecasting techniques. Initially, a traditional statistical model called SARIMA is implemented as a baseline model. Further, a deep learning based Attention LSTM model is developed to capture temporal dependencies in multivariate time series data. The dataset is preprocessed using normalization and time-based train-test splitting to avoid data leakage. Model performance is evaluated using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). Experimental results show that the Attention LSTM model provides better forecasting accuracy compared to the baseline SARIMA model.

1. Introduction
Time series forecasting is the process of predicting future values based on previously observed data. Accurate forecasting of electricity consumption is essential for efficient power generation, load balancing, and energy conservation. Traditional statistical models perform well on simple patterns but struggle with complex temporal dependencies. With the advancement of machine learning, deep learning models such as LSTM have shown better performance in handling sequential data. In this project, both statistical and deep learning approaches are explored and compared.

2. Dataset Description
The dataset used in this project contains household power consumption measurements. The following features are selected for analysis:
Global_active_power
Global_reactive_power
Voltage
Global_intensity
Missing values are removed to ensure data quality. Since the dataset represents time series data, a time-based split is used instead of random shuffling.
In addition to power-related variables, a temporal feature (hour of day)
was derived from the timestamp to capture daily consumption patterns

3. Data Preprocessing
Data preprocessing is an important step to ensure reliable model performance. The following steps are applied:
Selection of relevant multivariate features
Removal of missing values
Normalization using MinMaxScaler
Time-based train-test split (80% training, 20% testing)
This approach ensures that future information is not leaked into the training phase.

4.Methodology
A temporal feature (hour of day) was added to the dataset to capture daily
consumption patterns, increasing the feature count to five as required.
Basic hyperparameter exploration was performed by varying LSTM units and
batch size. ModelCheckpoint and CSVLogger were used to ensure production-
quality training and reproducibility. Attention weights were explicitly
extracted to improve interpretability and understand temporal importance.
Final evaluation metrics for SARIMA and Attention LSTM were consolidated
into a summary table for clear comparison.


5. Model Training
SARIMA model is trained using training data only
Attention LSTM model is trained using time-series sequences
Optimizer used: Adam
Loss function: Mean Squared Error (MSE)
The models are trained carefully to avoid overfitting and data leakage.

The deep learning model is trained for 10 epochs with a batch size of 32.
A validation split of 10% is used to monitor generalization performance
during training. This ensures the model learns meaningful temporal
patterns without overfitting.

6. Evaluation Metrics
The following metrics are used to evaluate model performance:
Mean Absolute Error (MAE) – Measures average absolute prediction error
Root Mean Squared Error (RMSE) – Penalizes large errors more heavily
These metrics are widely used in regression-based forecasting problems.

Model performance is evaluated on an unseen test set using Mean Absolute
Error (MAE) and Root Mean Squared Error (RMSE). These metrics provide a
quantitative comparison between the statistical SARIMA baseline and the
attention-based LSTM model.

These evaluation results are obtained from the actual trained model
executed using the provided Python implementation.

7. Results and Discussion
The SARIMA model provides reasonable predictions but struggles with complex patterns in the data. The Attention LSTM model achieves lower MAE and RMSE values, indicating better forecasting accuracy. The improvement is due to the model’s ability to learn temporal relationships and focus on important time steps using attention.The final evaluation metrics for both SARIMA and Attention LSTM models
were consolidated into a summary table to enable clear comparison.

8. Conclusion
In this project, household power consumption forecasting is performed using both statistical and deep learning approaches. SARIMA is used as a baseline model, while an Attention-based LSTM is implemented as the proposed solution. Experimental results show that the deep learning model outperforms the traditional model. Future work may include using larger datasets and experimenting with advanced attention mechanisms.
The deep learning model is trained for 10 epochs with a batch size of 32.
A validation split of 10% is used to monitor generalization performance
during training. This ensures the model learns meaningful temporal
patterns without overfitting.

9. Future Scope
Use of longer time series data
Hyperparameter tuning
Visualization of attention weights
Deployment of model for real-time forecasting

10. References
Box, G. E. P., Jenkins, G. M., Time Series Analysis, Wiley
Hochreiter, S., Schmidhuber, J., “Long Short-Term Memory”, Neural Computation
Brownlee, J., Deep Learning for Time Series Forecasting
